{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Requirements","metadata":{}},{"cell_type":"code","source":"%%writefile requirements.txt\nlangchain \nlangchain-community \nchromadb \nlanggraph\nlangchain-openai \nbitsandbytes\ngradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:31:42.418458Z","iopub.execute_input":"2025-08-02T19:31:42.418689Z","iopub.status.idle":"2025-08-02T19:31:42.423614Z","shell.execute_reply.started":"2025-08-02T19:31:42.418672Z","shell.execute_reply":"2025-08-02T19:31:42.422854Z"}},"outputs":[{"name":"stdout","text":"Overwriting requirements.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -qr requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:31:43.319807Z","iopub.execute_input":"2025-08-02T19:31:43.320568Z","iopub.status.idle":"2025-08-02T19:34:00.527832Z","shell.execute_reply.started":"2025-08-02T19:31:43.320529Z","shell.execute_reply":"2025-08-02T19:34:00.526933Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.2/152.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Import Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport chromadb\nimport requests\nimport json\nimport gradio as gr\nimport re\nimport numpy as np\n\nfrom datasets import load_dataset\nfrom chromadb.config import Settings\nfrom huggingface_hub import hf_hub_download\nfrom langchain_core.documents import Document\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModel, BitsAndBytesConfig\n\nfrom langchain_core.messages import HumanMessage, AIMessage, BaseMessage\nfrom typing import TypedDict, Annotated, Union\nfrom langgraph.graph.message import add_messages\nfrom langgraph.graph import StateGraph, START, END","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:34:02.726370Z","iopub.execute_input":"2025-08-02T19:34:02.726939Z","iopub.status.idle":"2025-08-02T19:34:41.457236Z","shell.execute_reply.started":"2025-08-02T19:34:02.726905Z","shell.execute_reply":"2025-08-02T19:34:41.456586Z"}},"outputs":[{"name":"stderr","text":"2025-08-02 19:34:24.999279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754163265.349687      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754163265.452371      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":5},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_parquet(\"hf://datasets/openai/openai_humaneval/openai_humaneval/test-00000-of-00001.parquet\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:34:41.458254Z","iopub.execute_input":"2025-08-02T19:34:41.458984Z","iopub.status.idle":"2025-08-02T19:34:47.512964Z","shell.execute_reply.started":"2025-08-02T19:34:41.458962Z","shell.execute_reply":"2025-08-02T19:34:47.512178Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           task_id                                             prompt  \\\n0      HumanEval/0  from typing import List\\n\\n\\ndef has_close_ele...   \n1      HumanEval/1  from typing import List\\n\\n\\ndef separate_pare...   \n2      HumanEval/2  \\n\\ndef truncate_number(number: float) -> floa...   \n3      HumanEval/3  from typing import List\\n\\n\\ndef below_zero(op...   \n4      HumanEval/4  from typing import List\\n\\n\\ndef mean_absolute...   \n..             ...                                                ...   \n159  HumanEval/159  \\ndef eat(number, need, remaining):\\n    \"\"\"\\n...   \n160  HumanEval/160  \\ndef do_algebra(operator, operand):\\n    \"\"\"\\...   \n161  HumanEval/161  \\ndef solve(s):\\n    \"\"\"You are given a string...   \n162  HumanEval/162  \\ndef string_to_md5(text):\\n    \"\"\"\\n    Given...   \n163  HumanEval/163  \\ndef generate_integers(a, b):\\n    \"\"\"\\n    G...   \n\n                                    canonical_solution  \\\n0        for idx, elem in enumerate(numbers):\\n    ...   \n1        result = []\\n    current_string = []\\n    ...   \n2                                return number % 1.0\\n   \n3        balance = 0\\n\\n    for op in operations:\\n...   \n4        mean = sum(numbers) / len(numbers)\\n    re...   \n..                                                 ...   \n159      if(need <= remaining):\\n        return [ n...   \n160      expression = str(operand[0])\\n    for oprt...   \n161      flg = 0\\n    idx = 0\\n    new_str = list(s...   \n162      import hashlib\\n    return hashlib.md5(tex...   \n163      lower = max(2, min(a, b))\\n    upper = min...   \n\n                                                  test  \\\n0    \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...   \n1    \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...   \n2    \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...   \n3    \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...   \n4    \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...   \n..                                                 ...   \n159  def check(candidate):\\n\\n    # Check some simp...   \n160  def check(candidate):\\n\\n    # Check some simp...   \n161  def check(candidate):\\n\\n    # Check some simp...   \n162  def check(candidate):\\n\\n    # Check some simp...   \n163  def check(candidate):\\n\\n    # Check some simp...   \n\n                 entry_point  \n0         has_close_elements  \n1      separate_paren_groups  \n2            truncate_number  \n3                 below_zero  \n4    mean_absolute_deviation  \n..                       ...  \n159                      eat  \n160               do_algebra  \n161                    solve  \n162            string_to_md5  \n163        generate_integers  \n\n[164 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_id</th>\n      <th>prompt</th>\n      <th>canonical_solution</th>\n      <th>test</th>\n      <th>entry_point</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HumanEval/0</td>\n      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>has_close_elements</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HumanEval/1</td>\n      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n      <td>result = []\\n    current_string = []\\n    ...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>separate_paren_groups</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HumanEval/2</td>\n      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n      <td>return number % 1.0\\n</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>truncate_number</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HumanEval/3</td>\n      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>below_zero</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HumanEval/4</td>\n      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n      <td>mean_absolute_deviation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>HumanEval/159</td>\n      <td>\\ndef eat(number, need, remaining):\\n    \"\"\"\\n...</td>\n      <td>if(need &lt;= remaining):\\n        return [ n...</td>\n      <td>def check(candidate):\\n\\n    # Check some simp...</td>\n      <td>eat</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>HumanEval/160</td>\n      <td>\\ndef do_algebra(operator, operand):\\n    \"\"\"\\...</td>\n      <td>expression = str(operand[0])\\n    for oprt...</td>\n      <td>def check(candidate):\\n\\n    # Check some simp...</td>\n      <td>do_algebra</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>HumanEval/161</td>\n      <td>\\ndef solve(s):\\n    \"\"\"You are given a string...</td>\n      <td>flg = 0\\n    idx = 0\\n    new_str = list(s...</td>\n      <td>def check(candidate):\\n\\n    # Check some simp...</td>\n      <td>solve</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>HumanEval/162</td>\n      <td>\\ndef string_to_md5(text):\\n    \"\"\"\\n    Given...</td>\n      <td>import hashlib\\n    return hashlib.md5(tex...</td>\n      <td>def check(candidate):\\n\\n    # Check some simp...</td>\n      <td>string_to_md5</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>HumanEval/163</td>\n      <td>\\ndef generate_integers(a, b):\\n    \"\"\"\\n    G...</td>\n      <td>lower = max(2, min(a, b))\\n    upper = min...</td>\n      <td>def check(candidate):\\n\\n    # Check some simp...</td>\n      <td>generate_integers</td>\n    </tr>\n  </tbody>\n</table>\n<p>164 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Embedding Model","metadata":{}},{"cell_type":"code","source":"embedding_model = HuggingFaceEmbeddings(\n    model_name=\"BAAI/bge-large-en-v1.5\",\n    model_kwargs={\"device\": \"cuda\"},  # Choose based on your setup\n    encode_kwargs={\"normalize_embeddings\": True}  # Important for BGE\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:34:47.513601Z","iopub.execute_input":"2025-08-02T19:34:47.513825Z","iopub.status.idle":"2025-08-02T19:35:01.956001Z","shell.execute_reply.started":"2025-08-02T19:34:47.513800Z","shell.execute_reply":"2025-08-02T19:35:01.955297Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/468533690.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  embedding_model = HuggingFaceEmbeddings(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc4f22e008624e6688d5635aed786c21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"642c4249ffb548aaa85b30b6bff9b47f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a857eeaa53c461a8d141756ab8f6881"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56b744dac01f41129ab19c29d9727e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a34d85822a40c2be0f49e57c9bcaca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27f80653191849b490dc8d612a4493bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73108fb626ed49a191cda88b70bababe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2f9b7a296b64aa8ae55da991a0bc65d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab424be481394f2ea4705f65ee66ce48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49db3441f1c34f7d8e40f76fd98a0b29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4514072ae764b85847eca1d4e4f5780"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# Chroma VectorDB","metadata":{}},{"cell_type":"code","source":"#HumanEval Dataset\ndocuments1 = [Document(page_content=prom, metadata={\"task_id\": task_id}) \n             for prom, task_id in zip(df[\"prompt\"], df['task_id'])]\nvectorstore = Chroma.from_documents(documents=documents1, embedding=embedding_model)\n\n#MBPP Dataset\ndataset_mbpp = load_dataset(\"mbpp\", split=\"test[:]\")\n\n\ndocuments2 = [Document(page_content=text, metadata={\"task_id\": task_id}) \n             for task_id, text in zip(dataset_mbpp[\"task_id\"], dataset_mbpp[\"text\"])]\nvectorstore.add_documents(documents2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:35:01.957253Z","iopub.execute_input":"2025-08-02T19:35:01.957520Z","iopub.status.idle":"2025-08-02T19:35:20.408456Z","shell.execute_reply.started":"2025-08-02T19:35:01.957492Z","shell.execute_reply":"2025-08-02T19:35:20.407645Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80927914c5fb446fb6777d9bfb37c49f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"full/train-00000-of-00001.parquet:   0%|          | 0.00/87.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdcfbc985234456e9fdc899137a3331a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"full/test-00000-of-00001.parquet:   0%|          | 0.00/116k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1413b616789409bafc7a8636fa380ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"full/validation-00000-of-00001.parquet:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24d49fa23b0b423e947d5f7c64abaefa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"full/prompt-00000-of-00001.parquet:   0%|          | 0.00/7.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a9ba0d43204592a65edf77b8d42bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/374 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d78fed182dd1491c95e8469ba38fbaec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"843ae409e95e4e87b5605ba0069d1a48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/90 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00023cdeb6244bf9912374892c5477d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating prompt split:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"530791127e3c4a51bae460ad3ee70f64"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['9b309e44-cb24-4e47-9560-19645c7431a3',\n '59345232-ece7-44cd-b548-b9f0f6c9dd6b',\n '1ac2db9e-8c38-46d1-b566-21860109eed6',\n 'a0221068-e63d-448e-acfc-ab2d27aa41df',\n '1943365b-c6a4-4fa8-811e-9145bd753f99',\n '629812ff-f18f-4801-a398-a7260abec802',\n 'fde66551-7294-466e-8859-03d0fe612aa8',\n '882fab48-a1ea-4c25-8e24-cebaaa7304e0',\n '8a8236cf-1def-4ab2-a9fc-cdede6fbae88',\n '45413964-d3d1-4b8c-a467-e17a3f39cbb9',\n 'ef4dd165-fd9f-4caa-9537-6a739047a5fd',\n '602e67a2-0e7f-44a4-8c7e-60afff8f8170',\n '8ee5919c-eddd-4733-a5c1-0614aa0bb1e1',\n '08c0277b-8e72-423a-8f47-d38043cd1dc4',\n '6ff78f3d-ef6f-4e53-8ebb-b3ca1b5dd0b8',\n '4f721fc6-7e6f-46ef-93e4-4e260f73c37f',\n 'eaef3ad2-0da8-4508-a51f-c6c396a01625',\n '0b3d32fe-962a-4863-9119-06d7086d12c3',\n '3dae8ddf-69da-4bbe-a47c-c8883de73fc8',\n '177e2453-fb0c-4350-8ea5-39814f2c6f71',\n 'ef697523-940d-4cc1-bab7-b7691aec1704',\n 'be72f2ff-3d7b-4e1c-bbe4-283faadfeb51',\n '799e7b77-09fe-4b25-a5ed-32f69c90b386',\n 'd217e853-ae38-4197-9f9b-07f18f265f68',\n 'c6b8695b-e69c-48d3-bfda-3327dab868d0',\n 'c5399bc7-95d2-4050-b42c-7a778a2beb4a',\n '797772fc-8faa-4199-8ec8-42e7f891dba3',\n '5cfc1324-88d9-4c6d-ae1f-3fef34e0237c',\n 'd6622224-97ff-4376-aa20-62ab92d547d9',\n '545eb695-4e61-40ea-9ac0-5e0bac8389c5',\n 'e65dab3d-1b88-46a1-b001-866f1f8320bd',\n '108fc630-974e-4ad4-acec-f8280fb1528f',\n 'ff5a82f9-088f-4e48-bcd6-edf6fe5c8c43',\n 'ef6bb2fe-73ba-43d4-8635-85f6688ae889',\n '149f1669-a5b5-4490-bc84-429cac0ddf6c',\n 'b9a0b606-1fac-4f60-999d-4fec252b6c59',\n 'b828070c-ab8d-4450-a38a-cbb0faef76ac',\n '034dc3f1-9f29-44f6-8659-5de7275c1149',\n '71c69cce-8148-441a-ba91-f60a7688f912',\n 'ccf7f2fb-ff8c-4ec6-a375-2fc5e743e893',\n '21e81be6-b3bc-473f-b7a0-175492f07d48',\n 'fc58d783-9926-46ed-a144-b33783392abc',\n '5c2c4ebe-6e48-4d08-afbc-efcfcd56e20b',\n '2078c6b0-cb0c-4a89-b5cc-194805b48b15',\n 'a74f53cf-b893-40db-ae17-a8e7ed3688b3',\n '27bbc09f-3de7-40d9-ba09-60752c333e24',\n 'df86e1cf-a032-415e-80ee-b74aac7dd9c2',\n '8153edf2-c3cc-44ff-a23e-c0f996937a73',\n 'e1902926-a15e-4a21-9d7c-a3bf72f952db',\n '8ca5bf20-b4b5-4d90-8cfe-01f0c54e2525',\n '4318302f-98e9-459d-b77e-e05bcd44e7b2',\n '2f6896d8-47b9-43e7-a5f5-a35a32b2d281',\n '3b2822dd-592f-43d1-badd-d902ef2686a1',\n '49b1dc92-bc0e-4114-ba35-33016072c0ba',\n '6f855b69-bada-43a1-bba6-f11d0ba26035',\n 'a7c49f2a-c4ef-494b-b2d7-6a887c8eb2d3',\n '40b680f8-8ff5-4585-b1aa-9bea31369903',\n '4753968d-4477-4ea6-b506-b38e56e92f1d',\n '53f85c28-fb0c-4eb3-bc84-c7bac22957d3',\n '9366aafc-74c1-46bc-9ef1-0e84181826b7',\n '0df048a4-6802-4382-8ad1-98841a2512e8',\n '5334108a-919e-4c28-aa13-8bbe853f4dea',\n 'ec3c7ee3-de92-4a6d-9696-f1f9e1f23fdd',\n 'd6ad59fb-b402-4be8-998c-2b1ac257fc43',\n 'd8c12189-5070-4c7c-a169-cb469b20e633',\n '2aa8f70c-511b-4988-8aad-b252758a2c0d',\n '64fa9e0e-072f-4712-a312-95e59f0bbe3e',\n 'b246f707-1b05-4101-884a-be1e1a9ea1e4',\n '36c4de97-5f00-496a-9e7b-d1f4adac499b',\n 'f45ecc6a-ad9c-4b06-9b6f-2fed52c3bdfb',\n '26eeb8e4-6542-4a49-b6a0-c82ee5349a3d',\n 'c6c899a4-a611-44a2-ad9a-70b5f2b24392',\n '4906bea2-4123-4393-b2bc-d37bac83a815',\n 'db09e577-8131-4e06-a4c6-989f1040634a',\n 'b7861a0c-dbe9-4bd8-8b51-ce4240b546b6',\n 'f15723b8-8da6-46c8-9fdf-adb8f6c50e72',\n 'b4fd0643-5e2f-443f-8f1b-7580c92adada',\n '5a43d72d-470d-428d-b36b-36f6a1229cb1',\n 'e1cf7494-5e4d-4aa2-946d-f16d19ad7e49',\n 'fab59fc8-a215-4dd0-939f-5b3509b0d34e',\n '9dae0bd8-b72c-497d-8953-9777504f99d8',\n 'ff78e037-be69-4e84-a127-7978ea96e02d',\n '73d37a3b-4d89-4fd1-8ac9-815b91cb3f9a',\n 'd1ca8f9a-6c4e-45a0-966e-5e2c8d391bcd',\n '5c7b2ed8-900e-4e20-b3f7-90f415721e03',\n '383255f8-c2a5-4809-8398-ba5fc58033fb',\n '109cf7ef-af93-4e7e-aafd-f28f5d7bdc29',\n '3e0857b5-36ac-4810-bad1-6dfcf50f1ea2',\n 'a520d803-df42-426e-bf78-ad4b776f4653',\n '8e73c895-2f42-42cd-a704-d82a24dd2eef',\n '821a3e28-81f4-4e9f-b8ab-7c387f8662f1',\n '861c89b8-1832-4bc4-9875-79b718bdafc3',\n '64b2abe6-a184-403a-b39f-e5ea0187064f',\n '3653f00e-c889-47ba-bbed-136c96ebabc2',\n '5b817992-ca14-4389-88b7-3b5a60f66627',\n 'c4ee6ade-3870-443e-b3cf-bd473c790443',\n '8f55b6b2-380a-42e0-bdce-1c9dcaa5ee51',\n 'ade9256d-7033-4961-acc9-4b9a51d17c26',\n 'bfd8dfb2-f857-4945-819f-2d47605bc360',\n '9c85d44f-fc9a-4f46-9ebd-306a6e07560c',\n 'ea32450f-386d-432b-b63c-a1199af2d22a',\n '711ef588-db7a-44fd-b930-474cb6952682',\n '525859bc-bd6b-4b33-bc4f-993e09c8e38e',\n '602edd45-7a72-4b08-b54d-a3e7d2e23323',\n '8a400e71-54b1-4232-8cfb-6ea1d9d90168',\n '19912864-d084-46be-a51a-436469d5d255',\n '2bd03af8-bb74-40cc-87ce-57b6c88ecdb3',\n '22d51b38-dc11-4d2b-8e4b-98c060befa7e',\n '5a9835a8-7e14-4763-8db1-d2183dce1ad0',\n 'e6874749-4827-4334-84da-0d13017351df',\n '5038ba07-124b-493e-8098-84e3d475e9dc',\n '453781e2-6a5b-4402-b3d6-5ea085320b31',\n '7529524d-a46c-4180-b647-af76e057b7d2',\n 'fe36a4c8-06f7-4ad5-b9e4-b6693c0e3413',\n '1bf716d4-4b26-48ed-8cdb-e7d60f739299',\n 'bf71c27f-6544-4479-892a-d4c8a1cd2e28',\n '24f0b159-efd9-4454-9ee7-cfe348795a94',\n 'e561057b-961b-4573-930f-b3985f80267b',\n '8f94341e-d312-4742-9dae-837ec7735a3f',\n '6e9439a8-dd2e-4aa5-8e4d-a473fc50dfa9',\n '59952f0a-9871-45e7-bae0-2d32134424fc',\n '57ee7d6e-6ae9-46d9-b321-e42cc1ac7b8e',\n '42ff97fc-fadb-43af-ba10-bbf17ec8c365',\n 'e0abe512-ea69-4837-ab64-3dc0453d2128',\n '825f89c4-a8a3-4378-9634-a63cec7e3b55',\n '9ab3a6e6-e5e2-412f-9e7d-063a8c3da200',\n '5f488179-9a6f-4ea2-b0bc-6293f051f4a6',\n '4ba8f9cb-8348-4cb9-ba58-32e5285796b7',\n '21eb091e-b1a0-4912-9b8e-f172ed9f58eb',\n '2105b8c6-1eee-474b-aed2-552f32de9e27',\n 'c11d2ed5-5625-46ff-9aba-5ec23e3d67a1',\n '1c65de99-ebbc-47f1-aac9-399ca1fd21e8',\n 'aa0c24c0-dda1-40f2-90d5-ba9b3631c6a5',\n 'c6151675-d7f5-46b0-ad03-acdfd2bcacc5',\n '0bfeab5b-b28f-48ee-a004-82ac73633297',\n 'c7212b08-b1bf-42fa-876d-c08896a7e957',\n '0f05ad03-1895-4911-8778-1148b7ef8ac1',\n 'fe804084-b191-416f-bd8e-0b313f8ab527',\n '63e938ec-eebc-49d2-8f50-76c854fa64af',\n '3860c4eb-3fac-4ed6-a134-f0f7907c5a90',\n '1b1a6d4d-a9f7-4047-ac81-95107a6188a7',\n '88fc6ea7-9bad-49af-9635-0341afc3c91c',\n '1d4bd7d4-362b-46bd-ab0c-704b39c11ee8',\n 'a0c26efb-c452-4b70-b65f-bfb4d1a94c87',\n 'f75c2517-2f61-42d4-a999-24bd312f978e',\n '787348f6-5e42-4495-8afd-89ba23420fbe',\n '127b35fc-a8f6-4df8-8267-54f7c5bf5717',\n '1fc0e68f-ca28-4f21-8ef8-a6ba4a6fb1b7',\n 'bb3c76e7-5099-4254-b371-ee5b5ed11294',\n '5e94f290-43f7-4f1f-9664-187d562593a6',\n 'e4c7c007-5f2f-466c-8ba9-0f542a0bf44d',\n '9d9d7f6b-dcbd-4552-8593-f455bb980e4e',\n 'a966b7e3-4be2-48a0-ac11-26e6d9c57fbc',\n '2a26e67c-b33d-403d-afd1-7af188faa6fd',\n '410eeede-b174-4fce-92c4-0df30b4db4fe',\n '66d4beb4-d2f6-4184-b40f-c9e751f56333',\n '006208e8-71ea-4dee-ac5d-3b7b74c63abf',\n '1c1c104b-7f82-42ae-a1be-792b1a2a0617',\n 'c950469e-7a5f-4754-b33b-40b40283feb7',\n 'cf689ea6-290b-46f1-a979-db5c12c17fb5',\n 'efca1966-3b1d-4244-86e6-70732eb5b2d1',\n 'f39fd968-fac9-48ed-a82a-a1726c5fc332',\n 'be1563db-9cf4-45ab-abf2-13ad42452018',\n '7dd6fd4a-41f3-4be1-9dd6-b2582059696d',\n '76302811-829a-4202-9fe9-aa8dae4b8c9f',\n 'f6949f1a-de9f-4e0b-950b-9c4864b577af',\n '3c1d5ead-a670-4394-a437-b19af485ff44',\n '657fa469-5bd9-4971-8cfa-26b6190827c5',\n 'c44077b2-807d-49ec-be5f-4381aed6eca5',\n '7afb7707-5585-416e-874f-dd6a43af1c94',\n '799cd6eb-1b31-4bfe-83c4-e0c8ba66d945',\n '6669bc86-9d68-4f16-85da-5934631662a8',\n '7faf981f-a57c-40f3-a081-2f0abcf1eaba',\n '2b27266b-b2ab-47c1-a9a0-6b4ca86ae9ac',\n '9dc59f11-8e7f-446f-9351-2befdc3d0573',\n 'cad492ad-0c6c-4055-8301-8d66b3b23656',\n 'b24b7fff-4b26-4f6b-83d5-dbf63ad12fb4',\n '2b18ebcd-3792-4ceb-824a-88463400429d',\n 'cebf53fa-8934-4d04-8c75-f26df880fbe3',\n '23d872ec-0560-4660-96e4-306deba9b581',\n '43aed5fc-0159-4bf6-87e2-1c53a9204ff7',\n 'dd1e48a4-a59c-484e-b40e-130258cf681a',\n '0dd623b2-7833-4242-a6f6-9158cd889868',\n 'f634b4fa-aec3-4a15-b29c-9ffb3510815d',\n '60a62ccf-e316-4486-b601-b11db608a352',\n 'd2a47844-de49-43c2-af63-13cbaf03cf19',\n 'd18824de-ba60-48d1-bac8-5cb80f0e813b',\n 'ee0d1e1c-5e3e-48b2-9dfe-a35f973c4186',\n '00a45682-57f1-48ea-887d-f07c062be63f',\n 'f127a537-b1b0-478a-aa66-56d7e2b1bed2',\n '2cbca130-e3b2-4660-951e-ae0c5dd20de0',\n '5f4b96f1-05ba-4d38-921f-63b90cd972d5',\n '3d66d928-5dd9-4c6e-88e2-c98990a7bf34',\n '85707b4c-a3a7-4577-bf36-175eaeee6d24',\n 'f45643f3-8bba-4ac8-9f2a-3b4fd05ae84b',\n '37957905-4b95-42f2-b9d5-5fe3d94ee87b',\n '077fbd86-fd35-4106-b029-cddbd5d26726',\n '135f9616-4afd-4610-b82b-654ebca253b2',\n '19b8dda7-d966-4efc-b55d-2611985f7e2e',\n '8f76b673-23c0-45a5-a4ea-eaab0b7b76a6',\n 'd2219e08-496e-47b4-962c-9895d8fea5af',\n 'bee309b9-8b55-43a5-8637-34c205981c04',\n '132eb1f9-885f-4ce7-93d3-d375df2ffcd1',\n 'cebcef09-e6dc-4cc0-b619-ce120da18e21',\n '70f44701-a60a-478e-94aa-a69a62c707fe',\n '318e8393-a39e-4440-b7ab-456f07558b7b',\n '851069a0-9dca-4dc4-bf31-a39f6a15f6f0',\n '596fd5c6-9f0c-41c0-9a1e-e1c2b1e3ec7b',\n 'bba9b256-d36e-4bc7-a6da-8862da9bebc5',\n 'b1b4ae2a-beca-4858-a9c8-717cf2015018',\n 'c1f12bce-1cc7-4bde-b8d0-df6ae0cb094a',\n 'bd5582e0-dc28-4f03-92e0-31df6e76dba5',\n '369fa50b-ec2f-4700-8c73-879e82b1ea80',\n '497ae1cf-cd53-465e-acf4-a9608352d7d9',\n '481e7f1f-a339-4cc5-9924-e4c9a90ccf89',\n 'd2bb074c-d23d-47d9-a74c-201e2b2f722f',\n '1e9ff0e0-353c-4df6-90d5-4784de79a769',\n '53dced86-c343-46aa-9146-a13bdcf00c63',\n '39d74601-0303-47f1-827a-7be8208168fc',\n '7b968299-cadd-47dd-aa36-cc5621124f60',\n 'de2d486e-d736-47e0-aec8-d239543b2133',\n '0ecbf1a7-4e22-4535-b567-a299c5d38772',\n 'df0f3966-7470-452e-847f-a6883f142975',\n '1e3e328b-73de-404e-acce-9a4a3b0dc2f1',\n '1a374178-3c1e-4e96-b8ad-06cf39163851',\n '7823b967-f7c0-43ec-a995-7463d2c6e441',\n 'e377e485-faeb-495e-900d-c9c5824c192b',\n '6c139c8a-1598-4893-9ce8-3c8d80da0b3c',\n 'b11a9a7a-7dd3-4d07-a0c5-6bd968ac1ca6',\n '93bf6f05-ce80-4fda-812d-bc80487d2d7f',\n '90092a29-45a7-4134-8282-ede289e3d9ce',\n '9142ad25-564d-48b4-a109-8b3fd8f19089',\n '7f758cce-8864-417a-8c86-429b40fc114f',\n '53963f86-c764-442e-9434-9f3046aa6d2a',\n '8d81302c-f3e5-40f5-bd71-d3b633e8f919',\n '361ed6a5-1e61-4ac9-ab96-e6c7467f0467',\n 'e0e7fd5f-4141-4b92-bbee-17f409c9ac8c',\n '660bbd35-a7a2-4780-8312-a5d32315aab8',\n '16c88353-86e7-489e-87bd-8e3bed808322',\n '28fe37cf-ca03-4bb8-b81e-db7e68b28fbd',\n 'aba1909a-b61d-4f5a-9a0b-a10407e18dd6',\n '27ca546b-c342-4e42-bfa0-2b744c5255af',\n '5b6aef5e-4e6a-4373-8029-45c449419b3b',\n '2e392dfe-0e11-42a6-93cd-8d59af1e1eb9',\n '4e92d065-1a65-4e4c-8cb3-15b561cb6a8a',\n 'ce040283-0de9-464c-88ee-55d121fa2bd4',\n 'bdb2b55f-9681-49ac-a991-640f408fed83',\n '24baea72-399b-49e6-829e-3600384d966d',\n '583edf15-b803-422b-82ce-6baa4e043b0f',\n 'd3ff32ca-6e0a-44e4-8d2d-91d32b61bfc0',\n '6515f8a1-c0e8-439b-931e-84447af2fbff',\n '2bcebf99-d35b-4bb0-b41b-a2b6f4dd40cb',\n 'ca577f2a-bb3e-4b84-9eed-e7792e1fad22',\n 'da9519dd-7c85-4ffb-aeb0-8dc0a1409af8',\n 'efbfba22-637d-4c60-bb47-c03d0a414120',\n 'fb475000-8305-44d4-9d53-0847c08895c7',\n '236652ef-2aa8-47b9-a31d-f22bf25751ae',\n '11bfe351-8c73-4846-92d1-1b5fc186db56',\n 'aa49cd23-d722-4426-8922-13929e257cce',\n 'ac6b529e-044c-442d-a96e-b1ba22075614',\n 'e910feba-93b5-48a5-baef-58810acae328',\n '50d7d299-d569-4d9a-8366-0398e0cb9e0c',\n 'ca77a010-9287-4794-b8f1-0d3abd77ecd6',\n '70dc2395-249e-4c83-8ee0-e410270c6378',\n '2b1e16bd-9c31-4d8d-a5ff-c92218c0ea1c',\n 'e4f1ae4a-60fd-4e38-bb80-79f1b2c1ab47',\n '916ad5c6-a391-4165-9f2a-7875db808846',\n '4ac7d515-5110-47e8-9c9b-c534a136b0ef',\n 'a1e12feb-865a-493f-94d1-fbc7862fc2c1',\n '7d79406f-bfc7-4d8f-82db-6095ebe8fc88',\n '4d2f1151-8b6f-4f21-bdf3-cfc43077b717',\n '15da099f-df9d-47bc-b0f0-bf383bd1e682',\n 'e3f7324e-c2b4-4b10-9def-f63bf776b150',\n 'be045d05-9901-46a0-ad69-1239da54c024',\n '3e451dc8-aef4-4b5a-879a-e4d2a78673c9',\n 'bc7ff533-24f7-4568-be31-dd8abf839eb6',\n '09ca22a8-696d-4408-959c-d9c7c3341345',\n '2853c5bc-626b-4f6f-a0a1-76c1abbfb34a',\n '8c0743fe-c319-4c9a-baf5-d1f8f9770dea',\n '8304e3b9-fda7-42b3-bb0d-d8ec2b2a01ec',\n 'd593c9d6-b3a0-4511-8ed1-4d4535c44320',\n '3332ade3-3011-47cb-a6d8-fbd695ef92b1',\n '20e52856-9dfe-4b0c-a7e7-86dc444e5ca9',\n 'aa5c9b59-f0b4-4e72-a17e-58fd4546ee28',\n 'ca855b89-eef6-4a9c-a7c5-35ee8c79c48b',\n '0fe537c3-250d-46da-8f96-b42ad30c9bc0',\n '1329ef27-01ee-408c-9867-757dd6954f2f',\n 'cbbdde5e-cc2f-4170-80e8-460018388f0d',\n 'd57ae7e5-c5ca-46bb-a06c-dcc8ba320620',\n '033771df-18a6-410a-be8c-5d19e7cd321b',\n '1990ab6c-63f2-464c-8ea8-573b62cf7b11',\n '6262af5f-ffde-4381-9b9f-ea9ada3a49dc',\n '97f56a96-699d-4b03-b95f-e63bc1eee7fc',\n '5cd5ed99-6da1-4e5b-ae2c-e1348fe7fe7e',\n '013e3e31-27c3-498c-96e4-8c3703eb729d',\n '2c1c948a-d52b-4da2-a0b0-f1c37c0bcb3a',\n '55a50d07-60ff-4694-8510-5359f8158e7a',\n '73f3c121-6e5c-451f-a1dc-ee641923871e',\n 'b334524f-6752-49d2-8c3e-4e4890e379c7',\n '443fe361-a142-4f91-91c9-30bcd5b58839',\n '60b57f9f-9af6-4adf-a993-95bfda32c06f',\n '14c12d8f-aece-41a0-b56a-b6b49ea1f639',\n 'b513bd58-8414-4db5-b751-fc5f8857a9be',\n '46ae510b-df9c-42eb-bc9e-2f039c5e93a0',\n '15a5e0ac-16e3-4063-982c-0407005b2e42',\n 'a6c4b2e2-7df0-4147-8d1b-03e7d6579a22',\n 'bdf9fe11-ccef-4390-821e-e0f7c0683c14',\n 'a01557b5-93e2-4a7e-ac48-d1de5c84e22c',\n '22ec51d8-2d1f-4b36-8b7c-bc86125e3acd',\n 'ad828f54-bdd2-412c-98eb-792b7c3e2c32',\n '55617f7b-5fc0-4624-b584-2ba8d5cd6d83',\n '116f5631-4659-43b4-91e0-5e94ac2db51d',\n '5eae0ac7-4bce-44db-bb6a-48f4be876a76',\n 'dbe1dac6-2fe5-4eb9-9291-dd5fa1ec6752',\n '7eed7add-3b7d-4c5e-9ef7-d89f7c94a68e',\n '335d9da8-9323-4df8-9d5d-82acc00e581a',\n '56a7345d-032e-4329-96de-4056e080b1b1',\n 'cf545edc-e320-49f6-afd4-83686873fecc',\n '202d7638-0fe9-4504-a149-18665995abf0',\n '5070676e-b10c-4c86-9505-720e0cf3af56',\n '13ba1375-c3b6-4210-882e-3703fb6f3a74',\n 'ac455d5a-3494-4851-8635-89547b7ce762',\n '9dbf8f1c-2536-4049-89c2-9fad443f68dd',\n '7e7afa02-dd36-45cd-bcd7-3d464a321e25',\n '1f6b381c-321e-4186-ae95-e09701ce3a16',\n '6733b04f-5df5-43db-897d-b44f31b9a429',\n 'dee94a03-582f-4fab-b19d-3d32f2f4ddb5',\n '88bfe2ce-c178-46c7-afe9-b6f63c48fcf6',\n '7cc80408-ef09-4d6e-b372-20dfa51d6cc0',\n '9147465c-7651-452f-8570-d1aee32c0d6c',\n 'c6390fc9-5375-401c-aacb-51f81f04b7d5',\n 'd27cedb7-242d-4b2e-a8a0-3a8586f21f6e',\n 'a4fe7258-8d44-4980-b4aa-9f1cca41ef08',\n 'e904a9f4-adbc-4e60-9d3a-1194e9b5dc61',\n 'dc5d816b-f4d1-4f11-bf3a-4144bc6a2c81',\n 'a29143a4-0c55-4d8f-97fb-18e0e8f9dae1',\n '5484a53d-b600-4117-b7cd-76bd94a81d9e',\n 'aad164b0-1ffe-44b7-bc9c-309c497b500a',\n '6cc64daf-2b0a-4768-aede-e6380c756a48',\n '34849841-0889-4f95-919d-d0afd58d2e6e',\n '603942e5-1a0b-440f-9079-77fd1f5a4f38',\n '833913a4-8af6-405b-b69e-c83f423702aa',\n '60508c5e-eef0-4a4c-be7c-b3390b8b5daf',\n '344c5f13-ef85-4aa3-901d-0728772218ff',\n '7aba5f06-8b63-43eb-ab78-de48549ae282',\n '8c063b40-6217-4347-ad8d-072cfcd96400',\n '32c873ec-579c-4c45-952f-91c5acba3b99',\n 'b673e6c7-6cc9-4b5c-8cd1-346d7079dc11',\n '42e0383b-562c-4e18-9b21-d2575fa1f36f',\n 'c32e7941-c3b4-4544-ba4a-79c60c54cd5a',\n '6e1d02c9-da0f-457b-bc16-6883fb420e51',\n '1f834b23-cd2f-41b3-a368-3507ef40ff60',\n '14d4f03e-546c-488b-b717-1cc8f29d66e1',\n 'c3ff0eb4-a071-426e-a9e0-a86d1e5c9d9d',\n '8cb1506c-c2d1-473f-964c-d47555ef71ee',\n 'e4dd3906-d3be-40e7-9434-6516effd0b97',\n 'eac9049e-9432-4e53-b997-b4461f5d669e',\n '505a2141-66ea-443b-86ac-3a0eb67a1f86',\n 'd19b76bf-c9ac-4234-bdc5-db4f04df0985',\n '967605da-7fed-439f-bfdc-f7db5b73e635',\n 'd74e4ee3-ab1d-4629-a550-657ef7929ab3',\n '7695b5e9-7462-418e-839c-7726e932a5bc',\n '1cb1fa35-3bdc-4b77-91ff-77645ea789cf',\n '3286e1b7-83ab-4d1e-9eaf-42ba7ff727e0',\n 'deefc18a-37b2-4f67-88d8-663920657697',\n '3fd61052-d57a-4361-8561-f1acdcafc935',\n '12c481ad-b6e1-463f-bd35-f021bfa8b26f',\n 'ab29c16a-9a40-4eff-a3cc-db2a25ec19f3',\n 'df886913-18db-44cd-be00-f3b2e82c6533',\n 'ca5fac04-bfbf-4557-a782-1089ef2f7f3f',\n 'ff87625f-4b9d-41aa-9d5c-f1ae4b43458f',\n '287e341d-a453-47d6-8953-09108aa077c4',\n 'b531ee5d-2af8-4d70-b40e-959d1136d9cf',\n '13a1cfd6-e6fd-4038-9674-53deb07d529a',\n '1dc7134e-1009-4e3b-bab3-54421467a294',\n 'b8266e16-4fb1-4912-84e2-e4ffd0d9c87e',\n 'd1b2f566-62c6-401b-85cc-195a1fdeb26a',\n '94b69f79-df2a-4f2d-a235-d9fb75973489',\n 'b0f8f1a1-48d4-4603-9c2a-b258e8cc3185',\n '47f577cc-74a9-47db-a8fd-92ed4b46330e',\n '3939dbc1-072a-425d-b4f5-666a95470acb',\n '67f55593-2498-4923-bfda-b4c49704de06',\n '3e67c115-47ec-4694-bb56-8eee1d6b4b3f',\n '6784f799-43dd-4830-bf9b-b6a752946eee',\n 'baa6667a-18a0-4530-9d27-71d2ea967a91',\n '8b5ec732-a838-44b9-8d2d-7bf4627a52fc',\n '6a23c91d-a489-446f-b0e8-95377a439c1f',\n 'c78a306d-f7e5-45e5-a525-f4c83164bb95',\n '6578c52d-a59e-4083-85b7-b3686184321e',\n '05519478-4623-4788-87a2-c859b26b0354',\n 'a2cfdd54-6e96-447a-8668-23d874715b11',\n '6c11c385-47b4-4f75-a30d-88d6aacad49a',\n '3c4e52df-c674-4cbd-84e0-7b674d0d6bfd',\n '92c84130-fd5e-4964-ac2d-5facf6903a00',\n 'fbb75200-8af2-439a-93aa-20616da2b1ee',\n '80f98a60-6190-4806-93eb-f370463b15ef',\n '0d317a9e-5aec-4a9f-a930-a9439a7a098e',\n '68802a2c-0e64-454a-8223-317ae31fd750',\n '0b40bc63-ff9c-425b-a673-6ed4f5a61507',\n 'ededcee1-aae4-4d34-91b2-12827f3db746',\n '97d39f1c-cd73-4579-98b7-005ee4369ca5',\n 'c5a0f189-2ea2-42d6-9bea-53014b53f219',\n 'b46c5c2c-3594-4187-8030-5954981b2052',\n 'c702018c-219f-4a95-b7a4-1bde4792bfec',\n 'f853f024-a1d7-4bab-b471-e662a0ab0346',\n '803ede1a-ae8c-4426-adfa-d2ccd5627567',\n '2820079b-99c4-4841-b776-854689c0c944',\n '1280fb0d-e5a6-41b1-8401-de111220c5ec',\n 'd9a1c8ee-7d04-49bb-8640-8d456021413f',\n 'ddc7fdc2-56c9-453c-a775-79c5c2f7f504',\n '814953dc-8bfc-4e78-9293-d48e70becda3',\n '551556c2-b13c-46bf-8679-aa8c25a776da',\n 'a99d0611-9cee-479d-b693-92e752c60d35',\n 'e98b7a48-a963-4009-b06e-865ecbfb2be7',\n 'cb4a7f51-18b8-4dc3-8f0f-f983e6594384',\n '474e839e-d23b-4803-b4ba-e5a43953183f',\n '523d4981-e7a3-4389-92d4-1a121e20bdb7',\n '2ac3265e-3088-49e3-9659-8d5505a9ab41',\n '360ebf77-7672-4eed-8b72-b27a2f600145',\n '5dc76e7f-fa73-4213-a88f-dbbe2220b8d8',\n '83fea51d-f631-4a54-9add-bff368203886',\n '0680f5c9-ea37-48db-bae9-74df04beec30',\n 'b55eb1c6-02cd-483c-acf5-190332e6d135',\n 'd5da84f4-f7df-4b88-b78b-3dbbb079e035',\n 'b82fdad9-40bd-46e4-8d58-3e55e5192c86',\n '144d2dea-6933-4b99-b967-90356367f879',\n 'a2446cb4-d64c-4e62-8141-ab6ca4a25055',\n '07ff8b07-24ba-4ace-a282-2e39dc19d4ef',\n '26c58658-cca1-4eb9-a998-7172f7e9e225',\n '99e663b9-048f-4d1f-9dbd-b4865ff7945e',\n '6369243f-030e-4962-aa59-4c38e4c8a1d9',\n 'e88f701e-3ce9-43d0-bd18-8c28d89f579c',\n 'dbcc0806-98cf-473e-8023-f26ab82e88d0',\n '2526aab2-817f-4c26-a166-c96042bcf60a',\n 'f968bebb-1538-4f39-8c99-98492c67bd41',\n '7991d12d-d6cc-4392-8a87-ed478c72af3f',\n '1ba002f5-b3eb-494c-9450-c34ab91a36f0',\n '9f3179e3-9dda-4edf-9df7-4985f5de5221',\n 'ff88fe35-956e-4b7f-a42c-47e6460b39a7',\n 'c8ed525b-178f-43ff-880b-9c593af63072',\n '04d7bfc9-f081-4f57-940a-9cfaa70ae7f1',\n 'ee14574d-11c2-49dc-b791-273b6b736944',\n '7623fa42-caba-413d-8a78-cc424e2e6bdb',\n '3725e464-5589-4182-aec9-45a4cd5a5ab0',\n 'f142b947-2ecd-4d4f-966e-c983cb67dc6d',\n '0910e365-f6d8-44ae-8f3d-dfe5e3670c04',\n '090b7f0b-fe4f-440b-bc11-faf256bd11c3',\n '8c0aeac7-32f6-4023-aa41-8663d48bdf14',\n 'e82e47c9-6b51-41b0-9cac-0dbf12b19ffe',\n 'ec5d5b6b-c670-49f6-af39-a40efcdfe846',\n 'd8f69951-8eea-4963-b4bd-737e0897e0af',\n 'f9d89340-7b14-4efd-bb8f-0dd4c4635c01',\n 'e0c82c29-bc8d-40fc-9ed1-47ab40806fdf',\n '7fb3f3b1-3a32-4165-8d8c-07279bf003d4',\n '476f83ca-b4cc-46d3-bcf7-f33fc75c443c',\n 'ef7ad4c3-20cc-4bab-9dab-b2613f574093',\n 'e77f35ba-df9f-493c-8484-9d64940be746',\n 'ddf3d000-3861-4743-9f96-9ff2da57ef70',\n '07217232-bc46-44f9-90a8-3ef290bf9186',\n '5772e7ec-fe9f-43ea-81af-e849d8ddbe6e',\n 'b7cc2302-ba4e-488b-a9e5-79957c957e8a',\n 'f799d981-1712-46dd-af7f-d5b31f814a47',\n 'a6562d57-ca2f-482c-8b28-77534c9fc4a5',\n 'cbcc2874-3bbe-4730-8d03-9aef2a36bbef',\n 'cec6f6af-90d9-4532-a8f0-b678eb36cc0c',\n 'a4f8af5b-3c33-46a2-8b83-4554d395bbce',\n 'eb87b7d9-693a-4d10-9dda-ecd1834d61bf',\n '16421e74-12f8-4c21-8f01-89b1b309915a',\n '8555f1e1-e88b-42e3-8404-4b637b7ac823',\n '48515052-6829-4ec5-8f76-f0ffb85a0383',\n '1e53c3fa-cdb6-4635-93e9-1dd0d6008735',\n '4935be71-a207-46d7-8f61-4c1e9957acca',\n 'd5a07661-d705-477d-9374-b35ca9baed97',\n 'f5def779-b6a1-441b-b71d-2a56252000f8',\n '17e64a37-428a-408d-b32d-b5dec94a333c',\n '8a8e99dd-0888-4943-a97c-bdf11b157c33',\n 'fc68971a-3594-4ea4-8a24-23c5e5e65868',\n '6d9e9fc9-f6aa-484b-8fc8-4a9b54a1016b',\n '99036eeb-6ca6-4b34-b179-77649b3f2483',\n 'c39e8472-0f81-4b73-805d-5c2cfa997133',\n '4bc98e0e-bb1a-4013-82dd-04aceb99970c',\n '10bc9e05-60b3-4d34-bb62-6c39ad86bfc8',\n '33da58ee-2540-46e8-a839-3be6ad313ddc',\n '3d536ae7-2dff-4135-8f19-90ebeb06601e',\n '150bbc0d-06af-4797-b1ac-494ff588ab27',\n '7f6baddb-1c62-4eea-a771-655929abf820',\n '9734f60c-079b-4a3e-9cc0-5c954956bd4e',\n '8ba9a7c0-33dd-4bc0-86d5-4e48019b2083',\n 'e31a5c4b-c322-4622-b7bc-eaaa90454149',\n '75fff295-5222-4311-bf33-48bdef495f9f',\n '9d6521e3-b738-4848-af93-1a734e40a398',\n 'dfd2d91b-9c63-4249-8e6a-fb59fb07b785',\n '4cac2148-e6c0-4978-93c1-51b87b7eae7d',\n 'd435e7e1-2786-48e5-b15b-d8479a6e3ee7',\n 'c7f0b7fd-6b89-403e-ab9a-a968a48e9a74',\n '01f79652-babd-40b5-97d4-948d9ef53ce9',\n '885fe2bf-f4f4-48ec-9c41-8b7922d57a6f',\n '530d6f5f-e2cd-4c3f-8a09-596940011a0b',\n 'b0fb4a3a-d68f-4e3d-ba70-eb75f70de8b5',\n 'a4204fab-a407-4e49-bb9e-6ab19d80c6c6']"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# Retriever","metadata":{}},{"cell_type":"code","source":"retrieved_docs = vectorstore.similarity_search(\"reverse a string\", k=1)\n\nfor doc in retrieved_docs:\n    print(\"Prompt:\", doc.page_content)\n    print(\"Task ID:\", doc.metadata[\"task_id\"])\n    print(type(doc.metadata[\"task_id\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:35:20.409772Z","iopub.execute_input":"2025-08-02T19:35:20.410033Z","iopub.status.idle":"2025-08-02T19:35:20.461805Z","shell.execute_reply.started":"2025-08-02T19:35:20.410015Z","shell.execute_reply":"2025-08-02T19:35:20.461217Z"}},"outputs":[{"name":"stdout","text":"Prompt: Write a function to reverse strings in a given list of string values.\nTask ID: 456\n<class 'int'>\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# LLM Generative Model\n","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-7B-Instruct\", trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-Coder-7B-Instruct\", trust_remote_code=True, quantization_config=BitsAndBytesConfig(load_in_4bit=True), device_map=\"auto\")\n\ngenerator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:35:25.972997Z","iopub.execute_input":"2025-08-02T19:35:25.973272Z","iopub.status.idle":"2025-08-02T19:38:18.807799Z","shell.execute_reply.started":"2025-08-02T19:35:25.973256Z","shell.execute_reply":"2025-08-02T19:38:18.807171Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2862e54c0f47dd9f84f9ff0ecc41ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0166cf0ad5a54981ac72b4d5c1715632"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91599d115fcc4e5aa29366b0d2ef1321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168aaa58c19d475db1a229a51d06af23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1a74b8c7a2f4332923ed1be8d77ab2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2e37e9a7b8847168f88ea3809054e9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36dbc8b4b04443068035b2a59fc68d91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0a1516c4c14dd0a94587b475d23e97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"424fcfdcba3746fba2766ac0115e8bb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb68cf24e52342e68c65b9393f6e61e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7029ac772eb147418a7491e414c91ccb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8739c00254e49b28e6159d4817a2fd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e2aa34e6c794c3da4101f76f861f7ea"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#function for generating code Using RAG\ndef generate_code(query, models=model, tokenizers= tokenizer):\n\n    docs = vectorstore.similarity_search(query, k=1)\n    context = [doc.page_content for doc in docs][0]\n    task_id = [doc.metadata['task_id'] for doc in docs][0]\n    \n    \n    if isinstance(task_id, int): \n        if context in dataset_mbpp['text']:\n            idx = dataset_mbpp['text'].index(context)\n            code = dataset_mbpp['code'][idx]\n            test_case = dataset_mbpp['test_list'][idx][0]\n            match = re.search(r'assert\\s+(\\w+)\\s*\\(', test_case)\n\n            if match:\n                function_name = match.group(1)\n                print(function_name)\n            \n        else:\n            code = None\n            print(\"None Issue\")\n    elif isinstance(task_id, str):\n        \n        if context in df['prompt'].values:\n            code = df[df['prompt'] == context][\"canonical_solution\"].values[0]\n        else:\n            code= None\n            print(\"None Issue\")\n    else:\n        code = None\n    \n    \n    prompt = f\"\"\"You are a Python code generator. Follow these precise instructions:\n    \n    1. Use the following functions in sequence when generating code:\n    {code}\n    \n    2. This is your function name:\n    {function_name}\n    3. Test output very well.\n    \n    4. Task:\n    {query}\n    \n    Only use the information provided above to generate Python code. Do not include explanations or any output other than the code itself.\n    \n    Your response should start with the Python code directly and end before test cases.\"\"\"\n\n\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are only a Python code generator\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer([text], return_tensors=\"pt\", max_length=500).to(model.device)\n    outputs = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:46:08.985922Z","iopub.execute_input":"2025-08-02T19:46:08.986203Z","iopub.status.idle":"2025-08-02T19:46:08.994651Z","shell.execute_reply.started":"2025-08-02T19:46:08.986183Z","shell.execute_reply":"2025-08-02T19:46:08.993621Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#function for generating code Using RAG\ndef generate_code_without_RAG(query, models=model, tokenizers= tokenizer):\n    docs = vectorstore.similarity_search(query, k=1)\n    context = [doc.page_content for doc in docs][0]\n    task_id = [doc.metadata['task_id'] for doc in docs][0]\n\n    if isinstance(task_id, int): \n        if context in dataset_mbpp['text']:\n            idx = dataset_mbpp['text'].index(context)\n            test_case = dataset_mbpp['test_list'][idx][0]\n            match = re.search(r'assert\\s+(\\w+)\\s*\\(', test_case)\n    \n            if match:\n                function_name = match.group(1)\n                print(function_name)\n    \n    prompt = f\"\"\"You are a Python code generator. Follow these precise instructions:\n    \n    1. This is your function name:\n    {function_name}\n    2. Test output very well\n    \n    3. Task:\n    {query}\n    \n    Only use the information provided above to generate Python code. Do not include explanations or any output other than the code itself.\n    \n    Your response should start with the Python code directly.\"\"\"\n\n\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are only a Python code generator\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer([text], return_tensors=\"pt\", max_length=500).to(model.device)\n    outputs = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:38:22.908989Z","iopub.execute_input":"2025-08-02T19:38:22.909724Z","iopub.status.idle":"2025-08-02T19:38:22.915977Z","shell.execute_reply.started":"2025-08-02T19:38:22.909680Z","shell.execute_reply":"2025-08-02T19:38:22.915347Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#function for explain code\ndef explain_code(code, models=model, tokenizers= tokenizer):\n    \n    prompt = f\"\"\"You are a Python code Explainer.\n    Explain the code only without anything else:\n------------------\n{code}\n------------------\n\nAnswer:\"\"\"\n\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a Python code Explainer.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:38:23.161948Z","iopub.execute_input":"2025-08-02T19:38:23.162170Z","iopub.status.idle":"2025-08-02T19:38:23.166873Z","shell.execute_reply.started":"2025-08-02T19:38:23.162153Z","shell.execute_reply":"2025-08-02T19:38:23.166181Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Evaluate LLM using Correcteness","metadata":{}},{"cell_type":"code","source":"# Remove opening ```python and closing ```\ndef clean_markdown_code_block(code_block: str) -> str:\n    lines = code_block.strip().splitlines()\n\n    # Remove ```python from the top if present\n    if lines and lines[0].strip().startswith(\"```python\"):\n        lines = lines[1:]\n\n    # Remove trailing ``` if present\n    if lines and lines[-1].strip() == \"```\":\n        lines = lines[:-1]\n\n    # Join lines and cut off anything after triple single or double quotes\n    cleaned_code = \"\\n\".join(lines)\n    for triple_quote in ('```'):\n        if triple_quote in cleaned_code:\n            cleaned_code = cleaned_code.split(triple_quote)[0]\n\n    return cleaned_code.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:38:26.178475Z","iopub.execute_input":"2025-08-02T19:38:26.179359Z","iopub.status.idle":"2025-08-02T19:38:26.183944Z","shell.execute_reply.started":"2025-08-02T19:38:26.179334Z","shell.execute_reply":"2025-08-02T19:38:26.183249Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# add test cases to ensure perfect execution\ndef evaluate_code_correctness(generated_code, test_list):\n    test_code = \"\\n\".join(test_list)\n    clean_code = clean_markdown_code_block(generated_code) + \"\\n\" + test_code\n    print(clean_code)\n    try:\n        exec(clean_code)\n        print(\"Excuted\")\n        return 1  # Correct\n    except Exception as e:\n        print(\"ERORRRRRRR\")\n        \n        return 0  # Incorrect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:38:26.587024Z","iopub.execute_input":"2025-08-02T19:38:26.587599Z","iopub.status.idle":"2025-08-02T19:38:26.591886Z","shell.execute_reply.started":"2025-08-02T19:38:26.587578Z","shell.execute_reply":"2025-08-02T19:38:26.591073Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#Evaluate our LLM withou RAG\nqueries = dataset_mbpp['text'][0:10]\ntests = dataset_mbpp['test_list'][0:10]\nacc_without = 0\ncount_without = 0\n\nfor query, test in zip(queries, tests):\n    code_generatded_cleaned = clean_markdown_code_block(generate_code_without_RAG(query))\n    acc_without += evaluate_code_correctness(code_generatded_cleaned, test[:])\n    count_without += 1\n    print(f'Executed - {acc_without}')\n    print(f'Step number = {count_without}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:40:47.767815Z","iopub.execute_input":"2025-08-02T19:40:47.768536Z","iopub.status.idle":"2025-08-02T19:42:30.373357Z","shell.execute_reply.started":"2025-08-02T19:40:47.768513Z","shell.execute_reply":"2025-08-02T19:42:30.372568Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"remove_Occ\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def remove_Occ(s, char):\n    first_occurrence = s.find(char)\n    if first_occurrence != -1:\n        s = s[:first_occurrence] + s[first_occurrence+1:]\n    last_occurrence = s.rfind(char)\n    if last_occurrence != -1:\n        s = s[:last_occurrence] + s[last_occurrence+1:]\n    return s\n\n# Test cases\nprint(remove_Occ(\"hello world\", \"o\"))  # Expected: hell wrld\nprint(remove_Occ(\"banana\", \"a\"))       # Expected: bnnan\nprint(remove_Occ(\"apple\", \"p\"))        # Expected: ale\nprint(remove_Occ(\"testcase\", \"z\"))     # Expected: testcase (no 'z' found)\nprint(remove_Occ(\"mississippi\", \"i\"))  # Expected: mississipp\nassert remove_Occ(\"hello\",\"l\") == \"heo\"\nassert remove_Occ(\"abcda\",\"a\") == \"bcd\"\nassert remove_Occ(\"PHP\",\"P\") == \"H\"\nhell wrld\nbnan\nale\ntestcase\nmssissipp\nExcuted\nExecuted - 1\nStep number = 1\nsort_matrix\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def sort_matrix(matrix):\n    return sorted(matrix, key=lambda row: sum(row))\nassert sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])==[[1, 1, 1], [1, 2, 3], [2, 4, 5]]\nassert sort_matrix([[1, 2, 3], [-2, 4, -5], [1, -1, 1]])==[[-2, 4, -5], [1, -1, 1], [1, 2, 3]]\nassert sort_matrix([[5,8,9],[6,4,3],[2,1,4]])==[[2, 1, 4], [6, 4, 3], [5, 8, 9]]\nExcuted\nExecuted - 2\nStep number = 2\ncount_common\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def count_common(dictionary):\n    from collections import Counter\n    word_counts = Counter(dictionary.values())\n    return word_counts.most_common()\nassert count_common(['red','green','black','pink','black','white','black','eyes','white','black','orange','pink','pink','red','red','white','orange','white',\"black\",'pink','green','green','pink','green','pink','white','orange',\"orange\",'red']) == [('pink', 6), ('black', 5), ('white', 5), ('red', 4)]\nassert count_common(['one', 'two', 'three', 'four', 'five', 'one', 'two', 'one', 'three', 'one']) == [('one', 4), ('two', 2), ('three', 2), ('four', 1)]\nassert count_common(['Facebook', 'Apple', 'Amazon', 'Netflix', 'Google', 'Apple', 'Netflix', 'Amazon']) == [('Apple', 2), ('Amazon', 2), ('Netflix', 2), ('Facebook', 1)]\nERORRRRRRR\nExecuted - 2\nStep number = 3\nfind_Volume\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def find_Volume(base, height, length):\n    return (base * height * length) / 2\n\n# Test cases\nprint(find_Volume(3, 4, 5))  # Expected output: 30.0\nprint(find_Volume(6, 8, 10)) # Expected output: 240.0\nprint(find_Volume(2, 2, 2))  # Expected output: 4.0\nassert find_Volume(10,8,6) == 240\nassert find_Volume(3,2,2) == 6\nassert find_Volume(1,2,1) == 1\n30.0\n240.0\n4.0\nExcuted\nExecuted - 3\nStep number = 4\nsplit_lowerstring\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"import re\n\ndef split_lowerstring(s):\n    return re.findall('[a-z][^a-z]*', s)\n\n# Test cases\nprint(split_lowerstring('helloWorld'))  # ['hello', 'World']\nprint(split_lowerstring('splitCamelCaseHere'))  # ['split', 'Camel', 'Case', 'Here']\nprint(split_lowerstring('oneTwoThree'))  # ['one', 'Two', 'Three']\nprint(split_lowerstring('noSplitNeeded'))  # ['no', 'Split', 'Needed']\nprint(split_lowerstring('alreadyLowercase'))  # ['already', 'Lowercase']\nassert split_lowerstring(\"AbCd\")==['bC','d']\nassert split_lowerstring(\"Python\")==['y', 't', 'h', 'o', 'n']\nassert split_lowerstring(\"Programming\")==['r', 'o', 'g', 'r', 'a', 'm', 'm', 'i', 'n', 'g']\n['h', 'e', 'l', 'l', 'oW', 'o', 'r', 'l', 'd']\n['s', 'p', 'l', 'i', 'tC', 'a', 'm', 'e', 'lC', 'a', 's', 'eH', 'e', 'r', 'e']\n['o', 'n', 'eT', 'w', 'oT', 'h', 'r', 'e', 'e']\n['n', 'oS', 'p', 'l', 'i', 'tN', 'e', 'e', 'd', 'e', 'd']\n['a', 'l', 'r', 'e', 'a', 'd', 'yL', 'o', 'w', 'e', 'r', 'c', 'a', 's', 'e']\nExcuted\nExecuted - 4\nStep number = 5\ntext_lowercase_underscore\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"import re\n\ndef text_lowercase_underscore(text):\n    pattern = r'^[a-z]+_[a-z]+$'\n    return bool(re.match(pattern, text))\n\n# Test cases\nprint(text_lowercase_underscore(\"hello_world\"))  # True\nprint(text_lowercase_underscore(\"Hello_world\"))  # False\nprint(text_lowercase_underscore(\"hello_World\"))  # False\nprint(text_lowercase_underscore(\"hello_world_2\"))  # False\nprint(text_lowercase_underscore(\"hello\"))  # False\nprint(text_lowercase_underscore(\"world\"))  # False\nassert text_lowercase_underscore(\"aab_cbbbc\")==('Found a match!')\nassert text_lowercase_underscore(\"aab_Abbbc\")==('Not matched!')\nassert text_lowercase_underscore(\"Aaab_abbbc\")==('Not matched!')\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nERORRRRRRR\nExecuted - 4\nStep number = 6\nsquare_perimeter\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def square_perimeter(side_length):\n    return 4 * side_length\n\n# Test cases\nprint(square_perimeter(5))  # Expected output: 20\nprint(square_perimeter(7))  # Expected output: 28\nprint(square_perimeter(1))  # Expected output: 4\nassert square_perimeter(10)==40\nassert square_perimeter(5)==20\nassert square_perimeter(4)==16\n20\n28\n4\nExcuted\nExecuted - 5\nStep number = 7\nremove_dirty_chars\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def remove_dirty_chars(str1, str2):\n    return ''.join([char for char in str1 if char not in str2])\n\n# Test cases\nprint(remove_dirty_chars(\"hello\", \"eo\"))  # Expected: \"hll\"\nprint(remove_dirty_chars(\"abcdefg\", \"adfg\"))  # Expected: \"bc\"\nprint(remove_dirty_chars(\"Python\", \"nohtyP\"))  # Expected: \"\"\nprint(remove_dirty_chars(\"123456789\", \"2468\"))  # Expected: \"13579\"\nassert remove_dirty_chars(\"probasscurve\", \"pros\") == 'bacuve'\nassert remove_dirty_chars(\"digitalindia\", \"talent\") == 'digiidi'\nassert remove_dirty_chars(\"exoticmiles\", \"toxic\") == 'emles' \nhll\nbce\n\n13579\nExcuted\nExecuted - 6\nStep number = 8\ntest_duplicate\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def test_duplicate(arr):\n    seen = set()\n    for num in arr:\n        if num in seen:\n            return True\n        seen.add(num)\n    return False\n\n# Test cases\nprint(test_duplicate([1, 2, 3, 4]))  # Output: False\nprint(test_duplicate([1, 2, 3, 3]))  # Output: True\nprint(test_duplicate([5, 5, 5, 5]))  # Output: True\nprint(test_duplicate([]))            # Output: False\nprint(test_duplicate([7]))           # Output: False\nassert test_duplicate(([1,2,3,4,5]))==False\nassert test_duplicate(([1,2,3,4, 4]))==True\nassert test_duplicate([1,1,2,2,3,3,4,4,5])==True\nFalse\nTrue\nTrue\nFalse\nFalse\nExcuted\nExecuted - 7\nStep number = 9\nis_woodall\ndef is_woodall(n):\n    if n <= 0:\n        return False\n    k = 0\n    while (k * (k + 1) // 2) < n:\n        k += 1\n    return (k * (k + 1) // 2) == n\n\n# Test cases\nprint(is_woodall(7))   # True, because 4*5/2 = 10 - 3 = 7\nprint(is_woodall(15))  # False, because no k satisfies k*(k+1)/2 = 15\nprint(is_woodall(1))   # True, because 0*(0+1)/2 = 1\nprint(is_woodall(0))   # False, because 0 is not considered in Woodall numbers\nprint(is_woodall(-5))  # False, because negative numbers are not considered\nassert is_woodall(383) == True\nassert is_woodall(254) == False\nassert is_woodall(200) == False\nFalse\nTrue\nTrue\nFalse\nFalse\nERORRRRRRR\nExecuted - 7\nStep number = 10\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"#Evaluate our LLM withou RAG\nqueries = dataset_mbpp['text'][0:10]\ntests = dataset_mbpp['test_list'][0:10]\nacc = 0\ncount = 0\n\nfor query, test in zip(queries, tests):\n    code_generatded_cleaned = clean_markdown_code_block(generate_code(query))\n    acc += evaluate_code_correctness(code_generatded_cleaned, test[:])\n    count += 1\n    print(f'Executed - {acc}')\n    print(f'Step number = {count}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:48:35.326228Z","iopub.execute_input":"2025-08-02T19:48:35.326826Z","iopub.status.idle":"2025-08-02T19:51:35.301256Z","shell.execute_reply.started":"2025-08-02T19:48:35.326799Z","shell.execute_reply":"2025-08-02T19:51:35.300606Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"remove_Occ\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def remove_Occ(s, ch):\n    for i in range(len(s)):\n        if s[i] == ch:\n            s = s[:i] + s[i+1:]\n            break\n    for i in range(len(s) - 1, -1, -1):\n        if s[i] == ch:\n            s = s[:i] + s[i+1:]\n            break\n    return s\n\n# Test cases\nprint(remove_Occ(\"hello world\", \"l\"))  # Expected: \"heo word\"\nprint(remove_Occ(\"banana\", \"a\"))       # Expected: \"bnnan\"\nprint(remove_Occ(\"testcase\", \"t\"))     # Expected: \"estcas\"\nprint(remove_Occ(\"single\", \"g\"))       # Expected: \"sinle\"\nprint(remove_Occ(\"nochange\", \"z\"))     # Expected: \"nochange\"\nassert remove_Occ(\"hello\",\"l\") == \"heo\"\nassert remove_Occ(\"abcda\",\"a\") == \"bcd\"\nassert remove_Occ(\"PHP\",\"P\") == \"H\"\nhelo word\nbnan\nescase\nsinle\nnochange\nExcuted\nExecuted - 1\nStep number = 1\nsort_matrix\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def sort_matrix(M):\n    result = sorted(M, key=sum)\n    return result\n\n# Test cases\nmatrix1 = [[3, 2, 1], [6, 5, 4], [9, 8, 7]]\nsorted_matrix1 = sort_matrix(matrix1)\nprint(sorted_matrix1)  # Output: [[3, 2, 1], [6, 5, 4], [9, 8, 7]]\n\nmatrix2 = [[1, 1, 1], [2, 2, 2], [3, 3, 3]]\nsorted_matrix2 = sort_matrix(matrix2)\nprint(sorted_matrix2)  # Output: [[1, 1, 1], [2, 2, 2], [3, 3, 3]]\n\nmatrix3 = [[-1, -2, -3], [-6, -5, -4], [-9, -8, -7]]\nsorted_matrix3 = sort_matrix(matrix3)\nprint(sorted_matrix3)  # Output: [[-1, -2, -3], [-6, -5, -4], [-9, -8, -7]]\nassert sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])==[[1, 1, 1], [1, 2, 3], [2, 4, 5]]\nassert sort_matrix([[1, 2, 3], [-2, 4, -5], [1, -1, 1]])==[[-2, 4, -5], [1, -1, 1], [1, 2, 3]]\nassert sort_matrix([[5,8,9],[6,4,3],[2,1,4]])==[[2, 1, 4], [6, 4, 3], [5, 8, 9]]\n[[3, 2, 1], [6, 5, 4], [9, 8, 7]]\n[[1, 1, 1], [2, 2, 2], [3, 3, 3]]\n[[-9, -8, -7], [-6, -5, -4], [-1, -2, -3]]\nExcuted\nExecuted - 2\nStep number = 2\ncount_common\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"from collections import Counter\n\ndef count_common(words):\n    word_counts = Counter(words)\n    top_four = word_counts.most_common(4)\n    return top_four\nassert count_common(['red','green','black','pink','black','white','black','eyes','white','black','orange','pink','pink','red','red','white','orange','white',\"black\",'pink','green','green','pink','green','pink','white','orange',\"orange\",'red']) == [('pink', 6), ('black', 5), ('white', 5), ('red', 4)]\nassert count_common(['one', 'two', 'three', 'four', 'five', 'one', 'two', 'one', 'three', 'one']) == [('one', 4), ('two', 2), ('three', 2), ('four', 1)]\nassert count_common(['Facebook', 'Apple', 'Amazon', 'Netflix', 'Google', 'Apple', 'Netflix', 'Amazon']) == [('Apple', 2), ('Amazon', 2), ('Netflix', 2), ('Facebook', 1)]\nERORRRRRRR\nExecuted - 2\nStep number = 3\nfind_Volume\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def find_Volume(l, b, h):\n    return (l * b * h) / 2\n\n# Test cases\nprint(find_Volume(3, 4, 5))  # Expected output: 30.0\nprint(find_Volume(6, 8, 10)) # Expected output: 240.0\nprint(find_Volume(2, 2, 2))  # Expected output: 4.0\nassert find_Volume(10,8,6) == 240\nassert find_Volume(3,2,2) == 6\nassert find_Volume(1,2,1) == 1\n30.0\n240.0\n4.0\nExcuted\nExecuted - 3\nStep number = 4\nsplit_lowerstring\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"import re\n\ndef split_lowerstring(text):\n    return re.findall('[a-z][^a-z]*', text)\nassert split_lowerstring(\"AbCd\")==['bC','d']\nassert split_lowerstring(\"Python\")==['y', 't', 'h', 'o', 'n']\nassert split_lowerstring(\"Programming\")==['r', 'o', 'g', 'r', 'a', 'm', 'm', 'i', 'n', 'g']\nExcuted\nExecuted - 4\nStep number = 5\ntext_lowercase_underscore\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"import re\n\ndef text_lowercase_underscore(text):\n    patterns = '^[a-z]+_[a-z]+$'\n    if re.search(patterns, text):\n        return 'Found a match!'\n    else:\n        return 'Not matched!'\nassert text_lowercase_underscore(\"aab_cbbbc\")==('Found a match!')\nassert text_lowercase_underscore(\"aab_Abbbc\")==('Not matched!')\nassert text_lowercase_underscore(\"Aaab_abbbc\")==('Not matched!')\nExcuted\nExecuted - 5\nStep number = 6\nsquare_perimeter\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def square_perimeter(a):\n    perimeter = 4 * a\n    return perimeter\nassert square_perimeter(10)==40\nassert square_perimeter(5)==20\nassert square_perimeter(4)==16\nExcuted\nExecuted - 6\nStep number = 7\nremove_dirty_chars\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"NO_OF_CHARS = 256\n\ndef str_to_list(string):\n    temp = []\n    for x in string:\n        temp.append(x)\n    return temp\n\ndef lst_to_string(List):\n    return ''.join(List)\n\ndef get_char_count_array(string):\n    count = [0] * NO_OF_CHARS\n    for i in string:\n        count[ord(i)] += 1\n    return count\n\ndef remove_dirty_chars(string, second_string):\n    count = get_char_count_array(second_string)\n    ip_ind = 0\n    res_ind = 0\n    temp = ''\n    str_list = str_to_list(string)\n    while ip_ind != len(str_list):\n        temp = str_list[ip_ind]\n        if count[ord(temp)] == 0:\n            str_list[res_ind] = str_list[ip_ind]\n            res_ind += 1\n        ip_ind += 1\n    return lst_to_string(str_list[0:res_ind])\nassert remove_dirty_chars(\"probasscurve\", \"pros\") == 'bacuve'\nassert remove_dirty_chars(\"digitalindia\", \"talent\") == 'digiidi'\nassert remove_dirty_chars(\"exoticmiles\", \"toxic\") == 'emles' \nExcuted\nExecuted - 7\nStep number = 8\ntest_duplicate\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"def test_duplicate(arraynums):\n    nums_set = set(arraynums)\n    return len(arraynums) != len(nums_set)\n\n# Test cases\nprint(test_duplicate([1, 2, 3, 4]))  # Output: False (no duplicates)\nprint(test_duplicate([1, 2, 3, 3]))  # Output: True (contains duplicates)\nprint(test_duplicate([5, 5, 5, 5]))  # Output: True (contains duplicates)\nprint(test_duplicate([]))            # Output: False (empty list)\nprint(test_duplicate([7]))           # Output: False (single element)\nassert test_duplicate(([1,2,3,4,5]))==False\nassert test_duplicate(([1,2,3,4, 4]))==True\nassert test_duplicate([1,1,2,2,3,3,4,4,5])==True\nFalse\nTrue\nTrue\nFalse\nFalse\nExcuted\nExecuted - 8\nStep number = 9\nis_woodall\ndef is_woodall(x):\n    if (x % 2 == 0): \n        return False\n    if (x == 1): \n        return True\n    x = x + 1 \n    p = 0\n    while (x % 2 == 0): \n        x = x / 2\n        p = p + 1\n        if (p == x): \n            return True\n    return False\n\n# Test cases\nprint(is_woodall(1))  # True\nprint(is_woodall(3))  # True\nprint(is_woodall(7))  # True\nprint(is_woodall(9))  # False\nprint(is_woodall(15)) # False\nprint(is_woodall(21)) # True\nprint(is_woodall(23)) # False\nassert is_woodall(383) == True\nassert is_woodall(254) == False\nassert is_woodall(200) == False\nTrue\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nExcuted\nExecuted - 9\nStep number = 10\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"print(f'Correctness of our LLM (without RAG) = {(acc_without / 10) * 100 }%')\nprint(f'Correctness of our LLM (wit RAG) = {(acc / 10) * 100 }%')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:51:38.483842Z","iopub.execute_input":"2025-08-02T19:51:38.484109Z","iopub.status.idle":"2025-08-02T19:51:38.488500Z","shell.execute_reply.started":"2025-08-02T19:51:38.484092Z","shell.execute_reply":"2025-08-02T19:51:38.487835Z"}},"outputs":[{"name":"stdout","text":"Correctness of our LLM (without RAG) = 70.0%\nCorrectness of our LLM (wit RAG) = 90.0%\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# LangGraph","metadata":{}},{"cell_type":"code","source":"class AgentState(TypedDict):\n    messages: list[Union[HumanMessage, AIMessage]]\n    \n    will_gen: int\n    will_exp: int\n    \n    query: Annotated[list[HumanMessage], add_messages]\n    code: Annotated[list[HumanMessage], add_messages]\n\n    gen: Annotated[list[AIMessage], add_messages]\n    exp: Annotated[list[AIMessage], add_messages]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:51:43.731965Z","iopub.execute_input":"2025-08-02T19:51:43.732209Z","iopub.status.idle":"2025-08-02T19:51:43.736481Z","shell.execute_reply.started":"2025-08-02T19:51:43.732193Z","shell.execute_reply":"2025-08-02T19:51:43.735770Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#Using a LLM model, we decide if the input is generation or explaination task \ndef inputs(state: AgentState) -> AgentState:\n    last_msg = state[\"messages\"][-1].content\n\n    # Define chat-style messages\n    messages = [\n        {\"role\": \"system\", \"content\": (\n            \"You are a smart classifier that decides if the user's intent is to generate code or explain code. \"\n            \"Respond ONLY with a JSON object in this format:\\n\"\n            '{ \"task\": \"generate\" or \"explain\", \"user_input\": \"<copy of user message>\" }'\n        )},\n        {\"role\": \"user\", \"content\": last_msg}\n    ]\n\n    # Call model\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n\n    # Extract JSON\n    try:\n        json_start = response.find(\"{\")\n        json_str = response[json_start:]\n        task_info = json.loads(json_str)\n    except Exception as e:\n        raise ValueError(f\"Failed to parse JSON from model: {raw_output}\") from e\n\n    task = task_info[\"task\"]\n    user_input = task_info[\"user_input\"]\n\n    if task == \"generate\":\n        state[\"will_gen\"] = 1\n        state[\"will_exp\"] = 0\n        state[\"query\"] = [HumanMessage(content=user_input)]\n    else:\n        state[\"will_gen\"] = 0\n        state[\"will_exp\"] = 1\n        state[\"code\"] = [HumanMessage(content=user_input)]\n\n    return state\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:51:43.917745Z","iopub.execute_input":"2025-08-02T19:51:43.917982Z","iopub.status.idle":"2025-08-02T19:51:43.924513Z","shell.execute_reply.started":"2025-08-02T19:51:43.917963Z","shell.execute_reply":"2025-08-02T19:51:43.923763Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def generate(state:AgentState) -> AgentState:\n    \"\"\"This function generate code using query\"\"\"\n    state['gen'] = [AIMessage(content=generate_code(state[\"query\"][-1].content))]\n    state['messages'].append(AIMessage(content=generate_code(state[\"query\"][-1].content)))\n    return state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:51:44.082503Z","iopub.execute_input":"2025-08-02T19:51:44.082746Z","iopub.status.idle":"2025-08-02T19:51:44.086699Z","shell.execute_reply.started":"2025-08-02T19:51:44.082699Z","shell.execute_reply":"2025-08-02T19:51:44.086186Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def explain(state:AgentState) -> AgentState:\n    '''This function explain the code'''\n    state['exp'] = [AIMessage(content=explain_code(state[\"code\"][-1].content))]\n    return state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:51:45.595885Z","iopub.execute_input":"2025-08-02T19:51:45.596522Z","iopub.status.idle":"2025-08-02T19:51:45.600422Z","shell.execute_reply.started":"2025-08-02T19:51:45.596495Z","shell.execute_reply":"2025-08-02T19:51:45.599637Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def decide_next_node(state:AgentState) -> AgentState:\n    '''This function decide to generate or explain the input'''\n    if state[\"will_gen\"] == 1:\n        return \"Generating\"\n    else:\n        return \"Explaining\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:51:45.826126Z","iopub.execute_input":"2025-08-02T19:51:45.826823Z","iopub.status.idle":"2025-08-02T19:51:45.830343Z","shell.execute_reply.started":"2025-08-02T19:51:45.826800Z","shell.execute_reply":"2025-08-02T19:51:45.829629Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"graph = StateGraph(AgentState)\n\ngraph.add_node(\"Input\", inputs)\ngraph.add_node(\"generate_code\", generate)\ngraph.add_node(\"explain_code\", explain)\ngraph.add_node(\"router1\", lambda state: state)\n\n\ngraph.add_edge(START, \"Input\") \ngraph.add_edge(\"Input\", \"router1\") \n\ngraph.add_conditional_edges(\n    \"router1\",\n    decide_next_node,\n    {\n        \"Generating\": \"generate_code\",\n        \"Explaining\": \"explain_code\"\n    }\n    \n)\n\ngraph.add_edge(\"generate_code\", END)\ngraph.add_edge(\"explain_code\", END)\n\napp = graph.compile()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:51:46.021516Z","iopub.execute_input":"2025-08-02T19:51:46.021781Z","iopub.status.idle":"2025-08-02T19:51:46.031590Z","shell.execute_reply.started":"2025-08-02T19:51:46.021751Z","shell.execute_reply":"2025-08-02T19:51:46.030856Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"# Schema","metadata":{}},{"cell_type":"code","source":"from IPython.display import Image, display\ndisplay(Image(app.get_graph().draw_mermaid_png()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:52:02.297043Z","iopub.execute_input":"2025-08-02T19:52:02.297692Z","iopub.status.idle":"2025-08-02T19:52:02.402782Z","shell.execute_reply.started":"2025-08-02T19:52:02.297662Z","shell.execute_reply":"2025-08-02T19:52:02.401913Z"}},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":33},{"cell_type":"markdown","source":"# Gradio Deployment","metadata":{}},{"cell_type":"code","source":"dataset_mbpp['text'][10:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:52:18.980890Z","iopub.execute_input":"2025-08-02T19:52:18.981155Z","iopub.status.idle":"2025-08-02T19:52:18.987083Z","shell.execute_reply.started":"2025-08-02T19:52:18.981136Z","shell.execute_reply":"2025-08-02T19:52:18.986417Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"['Write a function to find m number of multiples of n.',\n 'Write a function to find the first duplicate element in a given array of integers.',\n 'Write a python function to find the maximum sum of elements of list in a list of lists.',\n 'Write a function to convert the given binary number to its decimal equivalent.',\n 'Write a python function to find the product of non-repeated elements in a given array.',\n 'Write a function to check if the given tuple list has all k elements.',\n 'Write a python function to remove all digits from a list of strings.',\n 'Write a python function to find binomial co-efficient.',\n 'Write a python function to find the element occurring odd number of times.',\n 'Write a python function to count all the substrings starting and ending with same characters.']"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"chat_history = []\nexplain_generated = False\ndef chat_with_bot(user_input, history):\n    global chat_history, explain_generated \n\n    if explain_generated == True:\n        if user_input.lower() == 'yes':\n            result = app.invoke({\"messages\" : chat_history, \"will_exp\": 1})\n            explain_generated = False\n            return result['exp'][-1].content\n        else:\n            explain_generated = False\n            return 'Tell me what you need'\n            \n\n\n    chat_history.append(HumanMessage(content=user_input))\n    result = app.invoke({\"messages\" : chat_history})\n    chat_history = result['messages']\n\n    if result['will_gen'] == 1:\n        explain_generated = True\n        return result['gen'][-1].content + \"\\n\\n\" + \"Do you want from me to explain the code?\"\n        \n    elif result['will_exp'] == 1:\n        explain_generated = False\n        return result['exp'][-1].content\n\n\ngr.ChatInterface(\n    fn=chat_with_bot,\n    title=\"Code Helper Bot\",\n    description=\"Ask me to write or explain code. I can also explain generated code if you want!\",\n    theme=\"soft\"\n).launch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T19:52:26.681000Z","iopub.execute_input":"2025-08-02T19:52:26.681632Z","iopub.status.idle":"2025-08-02T19:52:29.136534Z","shell.execute_reply.started":"2025-08-02T19:52:26.681609Z","shell.execute_reply":"2025-08-02T19:52:29.136001Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n  self.chatbot = Chatbot(\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://1b59a1da52b86ade4a.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://1b59a1da52b86ade4a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"get_Odd_Occurrence\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"get_Odd_Occurrence\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nThe following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"}],"execution_count":36}]}